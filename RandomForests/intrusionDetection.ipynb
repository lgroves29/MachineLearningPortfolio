{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is meant as an introduction to random forests. Random forests are an ensemble method that can be used for supervised classification of data. After walking through the structure of a random forest algorith, we will apply the idea to a dataset of network intrusions to create an intrusion decection classifier. \n",
    "\n",
    "## Part 1: Building Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import seed\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image \n",
    "from pydot import graph_from_dot_data\n",
    "from six import StringIO\n",
    "\n",
    "import random\n",
    "\n",
    "from helperFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "For the sake of understanding, we will first walk through creating a random forest with an easy to understand dataset of dog breeds, with the goal of classifying them as good or not good for novice owners. Once we have built the understanding, we will then apply the algorithm to a less user friendly dataset of network activity. \n",
    "\n",
    "The dog dataset has 3 features: \"Easy to Train\", \"Kid Friendly\", and \"High Energy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easy To Train</th>\n",
       "      <th>Kid-Friendly</th>\n",
       "      <th>High-Energy</th>\n",
       "      <th>Good For Novice Owners</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afador</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affenhuahua</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affenpinscher</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghan Hound</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airedale Terrier</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Easy To Train  Kid-Friendly  High-Energy  \\\n",
       "Breed Name                                                   \n",
       "Afador                    False         False         True   \n",
       "Affenhuahua               False         False         True   \n",
       "Affenpinscher             False         False         True   \n",
       "Afghan Hound              False          True         True   \n",
       "Airedale Terrier           True          True         True   \n",
       "\n",
       "                  Good For Novice Owners  \n",
       "Breed Name                                \n",
       "Afador                             False  \n",
       "Affenhuahua                         True  \n",
       "Affenpinscher                       True  \n",
       "Afghan Hound                       False  \n",
       "Airedale Terrier                   False  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Binary Dog Data \n",
    "\n",
    "dog_pd = pd.read_csv(\"lab16data-binary.csv\", sep = \",\", index_col = \"Breed Name\")\n",
    "\n",
    "dog_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods\n",
    "\n",
    "These are methods in machine learning that use a group of methods to perform a task. First we run each method individually, then use some aggregate of their results to determine a final result. In the case of random forests, that means we create several trees to classify our data, then aggregate their classifications (perhaps by taking the most popular one) to get a final classification. It is common to use the majority to make this decision, but it is also possible to use a different voting system including weighting votes.\n",
    "\n",
    "#### How to get different results?\n",
    "Say we build several decision trees on the same dataset with the same classification purpose. We will get several copies of the same tree! We need to make each tree a little different by adding some element of randomness. What we can do is select a random subset of the features of the data. In this case since we only have 3 features, we can just build three trees, excluding one feature from the fit of each tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Splitting 391 data points on Kid-Friendly\n",
      ">Produces 288 True data points and 103 False data points\n",
      ">>Splitting 288 data points on Easy To Train\n",
      ">>Produces 160 True data points and 128 False data points\n",
      ">>Splitting 103 data points on None\n",
      ">>No best next split.\n"
     ]
    }
   ],
   "source": [
    "## Tree 1: Excluding \"High-Energy\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=['High-Energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Splitting 391 data points on Easy To Train\n",
      ">Produces 198 True data points and 193 False data points\n",
      ">>Splitting 198 data points on None\n",
      ">>No best next split.\n",
      ">>Splitting 193 data points on None\n",
      ">>No best next split.\n"
     ]
    }
   ],
   "source": [
    "## Tree 2: Excluding \"Kid-Friendly\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=['Kid-Friendly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Splitting 391 data points on Kid-Friendly\n",
      ">Produces 288 True data points and 103 False data points\n",
      ">>Splitting 288 data points on None\n",
      ">>No best next split.\n",
      ">>Splitting 103 data points on None\n",
      ">>No best next split.\n"
     ]
    }
   ],
   "source": [
    "## Tree 3: Excluding \"Easy To Train\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=['Easy To Train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating trees from different combinations of input variables gives us some idea of which variables are the most important to the classifications. For instance, 2 of the three trees we just built split on kid friendly first, which might indicate that kid-friendly is an important factor.\n",
    "\n",
    "### Pruning Trees\n",
    "Decision trees tend to overfit to their training data, creating giant trees with leaves at the bottom containing small subsets of the data.\n",
    "\n",
    "This is a question of the bias-variance trade-off. We defined models which exhibit high _variance_ as models that if we were to change the data slightly or show the model new data, then the tree may change drastically. Models with high variance (ie. those that are overfit to the data) are said to be hard to generalize. They also might simply contain too many rules or decisions for assigning a label (or class) to a datapoint. In a sense, to avoid overfitting, we want nice compact trees where each node contributes more to the classification than the effort of adding that node to the tree.\n",
    "\n",
    "One way to avoid overfitting with trees is to create **pruned** trees, where branches that do not contribute much to the tree are cut off. To do so we must first create the whole tree to determine which variables matter, then prune, rather than just creating short trees using the max_depth parameter.\n",
    "\n",
    "### sklearn for Decision Trees\n",
    "\n",
    "The sklearn module allows pruning of trees with the ccp_alpha parameter. Larger values result in more pruning. To experiment with this we need a larger dataset than the one we have used so far:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import full dog data\n",
    "dog_full_pd = pd.read_csv(\"lab16data.csv\", sep = \",\", index_col = \"Breed Name\")\n",
    "dog_full_np = dog_full_pd.to_numpy(dtype = np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Avg. Life Span, years</th>\n",
       "      <th>Wanderlust Potential</th>\n",
       "      <th>Adaptability</th>\n",
       "      <th>All Around Friendliness</th>\n",
       "      <th>Health And Grooming Needs</th>\n",
       "      <th>Physical Needs</th>\n",
       "      <th>Easy To Train</th>\n",
       "      <th>Kid-Friendly</th>\n",
       "      <th>High-Energy</th>\n",
       "      <th>Good For Novice Owners</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afador</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affenhuahua</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affenpinscher</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghan Hound</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airedale Terrier</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.33</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Size  Avg. Life Span, years  Wanderlust Potential  \\\n",
       "Breed Name                                                            \n",
       "Afador               4                     11                     4   \n",
       "Affenhuahua          1                     16                     2   \n",
       "Affenpinscher        1                     13                     2   \n",
       "Afghan Hound         4                     11                     5   \n",
       "Airedale Terrier     3                     12                     4   \n",
       "\n",
       "                  Adaptability  All Around Friendliness  \\\n",
       "Breed Name                                                \n",
       "Afador                     2.4                     3.00   \n",
       "Affenhuahua                3.0                     3.00   \n",
       "Affenpinscher              3.2                     3.33   \n",
       "Afghan Hound               4.0                     4.67   \n",
       "Airedale Terrier           2.2                     4.00   \n",
       "\n",
       "                  Health And Grooming Needs  Physical Needs  Easy To Train  \\\n",
       "Breed Name                                                                   \n",
       "Afador                                  3.2            4.00          False   \n",
       "Affenhuahua                             3.2            3.33          False   \n",
       "Affenpinscher                           2.4            3.33          False   \n",
       "Afghan Hound                            2.0            3.67          False   \n",
       "Airedale Terrier                        2.4            4.33           True   \n",
       "\n",
       "                  Kid-Friendly  High-Energy  Good For Novice Owners  \n",
       "Breed Name                                                           \n",
       "Afador                   False         True                   False  \n",
       "Affenhuahua              False         True                    True  \n",
       "Affenpinscher            False         True                    True  \n",
       "Afghan Hound              True         True                   False  \n",
       "Airedale Terrier          True         True                   False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view full dog data\n",
    "dog_full_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into the input variables and the target classes\n",
    "in_dog_data = dog_full_np[:,:-1]\n",
    "out_class = dog_full_np[:,-1]\n",
    "\n",
    "# Get the variable names \n",
    "var_names = list(dog_full_pd.columns)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare three decision tree classifiers, with alphas {0.1, 0.01, 0.001}\n",
    "dt1 = DecisionTreeClassifier(ccp_alpha = 0.001)\n",
    "dt2 = DecisionTreeClassifier(ccp_alpha = 0.01)\n",
    "dt3 = DecisionTreeClassifier(ccp_alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train three decision tree classifiers\n",
    "dt1.fit(in_dog_data, out_class)\n",
    "dt2.fit(in_dog_data, out_class)\n",
    "dt3.fit(in_dog_data, out_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydot.py:1923\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1922\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1923\u001b[0m     stdout_data, stderr_data, process \u001b[39m=\u001b[39m call_graphviz(\n\u001b[1;32m   1924\u001b[0m         program\u001b[39m=\u001b[39;49mprog,\n\u001b[1;32m   1925\u001b[0m         arguments\u001b[39m=\u001b[39;49marguments,\n\u001b[1;32m   1926\u001b[0m         working_dir\u001b[39m=\u001b[39;49mtmp_dir,\n\u001b[1;32m   1927\u001b[0m     )\n\u001b[1;32m   1928\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydot.py:132\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m program_with_args \u001b[39m=\u001b[39m [program, ] \u001b[39m+\u001b[39m arguments\n\u001b[0;32m--> 132\u001b[0m process \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[1;32m    133\u001b[0m     program_with_args,\n\u001b[1;32m    134\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m    135\u001b[0m     cwd\u001b[39m=\u001b[39;49mworking_dir,\n\u001b[1;32m    136\u001b[0m     shell\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    137\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m    138\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m    139\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m stdout_data, stderr_data \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucygroves/Desktop/Senior Year/Machine_Learning/Final Portfolio/RandomForests/intrusionDetection.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucygroves/Desktop/Senior%20Year/Machine_Learning/Final%20Portfolio/RandomForests/intrusionDetection.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m export_graphviz(dt1, out_file\u001b[39m=\u001b[39mdot_data, feature_names\u001b[39m=\u001b[39mvar_names)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucygroves/Desktop/Senior%20Year/Machine_Learning/Final%20Portfolio/RandomForests/intrusionDetection.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m (dt_vis, ) \u001b[39m=\u001b[39m graph_from_dot_data(dot_data\u001b[39m.\u001b[39mgetvalue())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucygroves/Desktop/Senior%20Year/Machine_Learning/Final%20Portfolio/RandomForests/intrusionDetection.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m Image(dt_vis\u001b[39m.\u001b[39;49mcreate_png())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydot.py:1733\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.new_method\u001b[0;34m(f, prog, encoding)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_method\u001b[39m(\n\u001b[1;32m   1730\u001b[0m         f\u001b[39m=\u001b[39mfrmt, prog\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog,\n\u001b[1;32m   1731\u001b[0m         encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1732\u001b[0m     \u001b[39m\"\"\"Refer to docstring of method `create`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1733\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m   1734\u001b[0m         \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mf, prog\u001b[39m=\u001b[39;49mprog, encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydot.py:1933\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1930\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(e\u001b[39m.\u001b[39margs)\n\u001b[1;32m   1931\u001b[0m     args[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{prog}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m not found in path.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1932\u001b[0m         prog\u001b[39m=\u001b[39mprog)\n\u001b[0;32m-> 1933\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1935\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "# graph dt1 (ccp_alpha = 0.001)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dt1, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dt2 (ccp_alpha = 0.01)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dt2, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dt3 (ccp_alpha = 0.1)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dt3, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Random Forest\n",
    "With this intuition about pruning and taking results from multiple trees, we can now move on to random forests.\n",
    "\n",
    "A random forest classifies data based on a majority vote from a grove of pruned, random decision trees. We can start by creating 3 pruned decision trees with 4 randomly chosen features per tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build three trees with the same criteria\n",
    "seed(2022)\n",
    "dt1 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)\n",
    "dt2 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)\n",
    "dt3 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all three - due to randomness, will be different trees\n",
    "dt1.fit(in_dog_data, out_class)\n",
    "dt2.fit(in_dog_data, out_class)\n",
    "dt3.fit(in_dog_data, out_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for the first ten dogs using the first classifier\n",
    "dt1.predict(in_dog_data[:10,:])\n",
    "\n",
    "# predict for the first ten dogs using the second classifier\n",
    "dt2.predict(in_dog_data[:10,:])\n",
    "\n",
    "# predict for the first ten dogs using the third classifier\n",
    "dt3.predict(in_dog_data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifications of our three trees on this dog (where 1 means a dog that IS good for novice owners) were 1, 0,0. Voting by simple majority, this dog is not good for novice owners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Random Forest Intrusion Detection System\n",
    "\n",
    "Having seen how a random forest works, we can now use sklearns built in method for creating one. Since we already have an intution gained from working with this straightforward dog data set, we can now pivot to working with the network activity dataset. This data records TCP/IP connections in an LAN network, with variables including protocol, application accessed, size of packet, etc. We will build a random forest on this data, then test its performance as an intrusion dection system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/0nnwfhvd6rn_f569pqrzdsvw0000gn/T/ipykernel_60196/1279583825.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[column][dataset[column] == var] = replacements[var]\n"
     ]
    }
   ],
   "source": [
    "# Import new dataset\n",
    "data = pd.read_csv(\"Train_data.csv\")\n",
    "data_wrangle(data, [\"protocol_type\", \"service\", \"flag\", \"class\"])\n",
    "data_np = np.array(data)\n",
    "training_index = random.choices(range(len(data_np)), k = 4500)\n",
    "training_np = data_np[training_index, :].astype('int')\n",
    "\n",
    "testing_index = list(set(range(len(data_np)))-set(training_index))\n",
    "testing_np = data_np[testing_index, :].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "25187    1\n",
      "25188    1\n",
      "25189    1\n",
      "25190    1\n",
      "25191    1\n",
      "Name: class, Length: 25192, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(training['class'])\n",
    "#training_np[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grove = RandomForestClassifier(n_estimators=10, max_features=10, max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = training_np[:, :-1]\n",
    "out_class = training_np[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=10, n_estimators=10,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our model to the data\n",
    "grove.fit(in_data, out_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006219141663501709\n"
     ]
    }
   ],
   "source": [
    "predictions = grove.predict(testing_np[:, :-1])\n",
    "\n",
    "print(classification_mse(testing_np[:, -1], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007333333333333333\n",
      "0.0077777777777777776\n",
      "0.006888888888888889\n"
     ]
    }
   ],
   "source": [
    "# compare some different configurations of number of estimator trees\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 10, max_features = 10, max_depth = 10))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 20, max_features = 10, max_depth = 10))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 10, max_depth = 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008222222222222223\n",
      "0.008222222222222223\n",
      "0.009555555555555557\n"
     ]
    }
   ],
   "source": [
    "# different configurations of max_features\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 5, max_depth = 10))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 12, max_depth = 10))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 8, max_depth = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017777777777777778\n",
      "0.006222222222222222\n",
      "0.006666666666666666\n",
      "0.0064444444444444445\n"
     ]
    }
   ],
   "source": [
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 10, max_depth = 5))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 10, max_depth = 15))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 10, max_depth = 18))\n",
    "print(randomForestCV(training_np[:, :-1], training_np[:, -1], 10, n_estimators = 15, max_features = 10, max_depth = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some perhaps overly finnicky variations and cross validation to improve cross val performance by a tiny fraction, it seems that a random forest with 15 estimators, 10 random features, and a max depth of 15 will generally perform very well. Let's now train a model with those hyper parameters on the full dataset and test it with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005222180022787694\n"
     ]
    }
   ],
   "source": [
    "final_grove = RandomForestClassifier(n_estimators=15, max_features=10, max_depth=15, random_state=0)\n",
    "final_grove.fit(training_np[:, :-1], training_np[:, -1])\n",
    "final_predictions = final_grove.predict(testing_np[:, :-1])\n",
    "\n",
    "print(classification_mse(testing_np[:, -1], final_predictions))\n",
    "#out of curiosity, let's count percentages of false pos/false neg\n",
    "# 1 = anomaly, 0 = normal\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "for i in range(len(final_predictions)):\n",
    "    if final_predictions[i]!=testing_np[i, -1]:\n",
    "        if final_predictions[i]> testing_np[i, -1]:\n",
    "            false_pos = false_pos + 1\n",
    "        else:\n",
    "            false_neg = false_neg + 1\n",
    "false_pos = false_pos/len(final_predictions)\n",
    "false_neg = false_neg/len(final_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015191796429927839\n",
      "0.003703000379794911\n"
     ]
    }
   ],
   "source": [
    "print(false_pos)\n",
    "print(false_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained a random forest on network connections that can classify activity as normal or anomalous with a means squared error of about .005, which indicates a very accurate classifier. Of course, in a real-world implementation, flagging  ~.15% of normal network traffic as anomalous may waste valuable resources investigating harmless activity, and disregarding ~.4% of anomalous behaviour as normal may allow a damaging attack to go undetected, but it is also possible that a commercial intrusion detection system would have a more finely calibrated classifier trained on a larger dataset. This classifier serves to illustrate how those real-world IDS's can work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "171f1315d85f83bcf4a5b0908b4de5fe5826324d192e6e54d7eda8a12c15ea07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
